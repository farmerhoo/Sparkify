# Sparkify项目报告

## 1. 项目简介

### 1.1 背景

本项目为优达学城数据挖掘纳米学位班的毕业项目，项目是分析一个音乐应用Sparkify的用户流失情况，并根据提供的结构化数据预测用户流失情况。项目既可以在128MB的迷你数据集上完成，也可以选择在完整的12GB的数据集上完成。考虑到便捷性，我这里先使用迷你数据集在本地完成项目，后续可以直接迁移至大型的完整数据集上。

完整数据集高达12GB，不能使用小数据集的scikit-learn、pandas等数据科学包在本地完成处理，因此使用Spark来进行数据的预处理、探索性数据分析(Exploratory Data Analysis, EDA)和建模预测等任务，熟悉通过pyspark包进行大规模的数据分析任务。

### 1.2 项目结构

本项目首先导入项目相关的迷你用户数据集，对数据进行简单的处理发现数据集的大小为286500行18列，也就是说提供的数据包含286500份用户在Sparkify应用程序上的交互数据，每一份数据包含18个特征。接下来我对项目的数据进行清理、删除缺失值和创建用户是否流失的标记列(churn列)等操作，为进一步的探索性数据分析做准备。通过探索性数据分析，初步了解到与用户流失有一定相关性的特征，这些特征就是特征工程中所使用的基础特征，特征工程将上述特征转换为便于机器学习模型训练的特征向量。最后，使用逻辑回归、随机森林和提示树三个模型在训练数据集上预测用户是否流失，并通过模型在测试数据集上的表现选择模型，使用选择的模型对验证集上的数据进行预测，并给出模型预测的评分。

### 1.3 项目代码

项目代码可以在Git-hub上查看：<https://github.com/farmerhoo/Sparkify>

## 2. 初步处理数据

### 2.1 理解特征的实际意义

本次数据分析使用的为迷你数据集，数据大小为$28650 \times 18$

初步查看每个特征后，按照数值型数据和类别型数据给出每个特征的可能取值和实际意义如下所示：
​    - 数值型数据：
​        - userId(string): 用户ID
​        - ts(long): 记录时间的timestamp
​        - sessionId(long): 每次打开app创建一个sessionId
​        - length(double): 歌的长度
​        - itemInSession(long): Session中的项目数量
​        - registration(long): 注册时间timestamp

- 类别型数据：
    - artist(string): 艺术家
    - auth(string): 用户身份验证状态，比如Logged In状态
    - firstName(string): 用户的名字
    - gender(string): 用户性别
    - lastName(string): 用户的姓
    - level(string): 有free和paid两种
    - location(string): 用户的定位
    - method(string): HTTP请求方式，PUT和GET两种
    - page(string): 页面名称，Home, Upgrade, Downgrade等
    - song(string): 歌曲名称
    - status(long): 请求状态，200、307、404这三种
    - userAgent(string): 用户浏览器


### 2.2 清理数据

首先，根据对数据的观察，发现缺失值存在三种情况：1. NaN，Not A Number；2. NULL，空值；3. '', 空字符串。

根据对缺失值的分析发现：userId、firstName、gender、lastName、location、registration、userAgent列的缺失值数量是相同的，可以看出这些特征都是用户的信息；而其他的存在缺失值的特征为artist、length和song，他们的缺失值数量也是相同的，并且可以看出特征均为歌曲相关的信息。

删除缺失值时，因为用户信息列的确实对数据分析影响更大，而且对后续的用户流失分析贡献很小，我们就删除了userId列存在缺失值的所在行，对于歌曲信息列存在缺失值的情况暂时不做处理。

## 3. 探索性数据分析

### 2.1 单变量分析

1. 用户的性别分布如下图，男性用户略多于女性用户。

![图片](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200531225032.png)

2. 用户交互次数的分布如下图所示，可以发现大多数用户的交互次数都在2000以内，个别用户的交互次数特别多，这类用户的流失可能性应该是偏小的。

![1590936757232](C:\Users\huqua\AppData\Roaming\Typora\typora-user-images\1590936757232.png)

3. 打开APP次数的分布直方图如下图所示，从图中可以看出打开APP次数看起来像一个长尾分布或泊松分布，数据集的这段时间内大多数用户打开APP的次数在20次以内。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200601213110.png)

4. 根据单变量的探索性分析，还可以得出如下结论：
   - 本数据集总共有225个独立的用户，流失的用户占比为23.11%
   - 本数据集中在该软件上交互次数最多的用户ID为39
   - 本数据集中用户的交互次数为长尾分布，大多数用户的交互次数在2000次以下
   - 本数据集包含的艺术家数量为17656
   - 本数据集包含的歌曲数量为58481
   - 本数据集播放量最高艺术家是Kings Of Leon
   - 本数据集播放量最高的歌曲是You're The One，排名第二的Undo我也经常听，哈哈
   - 本数据集大多数用户都处于登陆（Logged in）状态
   - 本数据集的用户中男性用户略多余女性用户
   - 本数据集的用户大都在付费状态下进行操作，说明软件的付费比率还是比较高的
   - 本数据集中软件使用量排名最高的三个城市分别是：洛杉矶、纽约和波士顿
   - 本数据集中访问最多的页面是Next Song页面，其次是Thumbs Up点赞页面，再次是Home页面及主页
   - 本数据集中用户的请求有252个返回404，可能存在部分需要修复的页面
   - 本数据集包含用户在2018年10月1日至2018年12月31日的交互数据

### 2.2 多变量分析

1. 如下图所示，流失用户所听艺术家的歌曲数量相对较少。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200601213654.png)

2. 留存用户中男女比例接近，流失用户中男性略多于女性，如下图所示。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200601213745.png)

3. 付过费的用户流失率略低，说明付过费的用户更认可该产品，也可能是因为产品得到了认可才付费的。如下图所示。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200602210419.png)

4. 流失用户所听歌曲数量相对较少，如下图所示。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200602210449.png)

5. 流失用户添加歌曲至播放清单的数量相对更少，如下图所示。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200602210530.png)

6. 流失用户添加朋友的数量相对更少，如下图所示。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200602210603.png)

7. 流失用户的交互次数相对更少，如下图所示。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200602210626.png)

8. 流失用户打开app的次数相对更少，如下图所示。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200602210649.png)

9. 流失用户注册天数明显更短，如下图所示。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200601214030.png)

10. 流失用户注册天数明显更短，如下图所示。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200601214100.png)

## 4. 特征工程

根据探索性分析的结果，选取部分特征用于建模。这些特征在训练模型前需要先进行特征工程，将特征转换为适合模型训练的向量类型，以下分为数值型特征和类别型特征分别进行讨论。

### 4.1 数值型特征

根据以上的分析，创建如下几个数值型特征
- 听歌数量(numSongs)：认为每点击一次NextSong表示听歌一首
- 播放清单歌曲数量(numInList)：认为每点击一次Add to PlayList添加一首歌曲
- 添加朋友数量(numFriends)：认为每点击一次Add Friend添加一个朋友
- 打开app次数(numSession)：认为一个新的sessionId表示打开一次app
- 注册天数(regDay)：注册时间到认为最后一次打开app的记录的天数

### 4.2 类别型特征

根据以上分析，创建以下几个类别型特征：
- 性别特征(gender)
- 用户级别(level)
- 用户定位特征(location)，因定位的格式一般为"locPart1, locPart2", 因此分为两部分处理
    - 定位前半部分(locPart1)
    - 定位后半部分(locPart2)

## 5. 建模

### 5.1 评价指标

适合二分类的评估指标有准确率、精确率、召回率、F1和ROC曲线下面积AUC等指标，下面先对这几个指标简单进行介绍。在讨论之前，我们可将样例根据真实类别和预测类别分为以下四类：真正例（TP）、假正例（FP）、真负例（TN）、假负例（FN）分类结果的==混淆矩阵==如下表所示。

![表1. 分类结果的混淆矩阵](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20190107211859.png)

**准确率（accuracy）**

准确率是分类正确的样本占总样本的比率。准确率指标不适合作为非对称样本的评估指标，考虑非对称样本的极端情况，比如负样本的占比为99%，那么模型对认为所有的样本都是负样本也可以获得99%的accuracy，而这显然是不合理的。

**精确率（precision）**

精确率是指在预测为正例的样本中实际为正例所占的比率，公式表示如下所示。

$$P = \frac{TP}{TP+FP}$$

同样精确率不适合作为非对称样本的评估指标，比如对于正例占比很高的样本，模型很容易获得较高的precision。

**召回率（recall）**

召回率是指在所有的实际正例样本中，模型成功预测出的正例所占的比率，公式表示如下所示。

$$R = \frac{TP}{TP+FN}$$

同样召回率率不适合作为非对称样本的评估指标，比如对于正例占比很高的样本，模型很容易获得较高的recall。

**F1-Score和P-R曲线**

F1-Score是F1参数在计算Precision和Recall的调和平均，同时考虑了Precision和Recall的重要性。其计算公式所示：

$$F1 = \frac{2 \times P \times R}{P+R}$$

以查准率为纵轴、查全率为横轴，就可以做出如下的P-R曲线：
![图1. PR曲线](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20190107213441.png)

**ROC和AUC**

ROC全称“受试者工作特征(Receiver Operation Characteristic)”曲线，不同于P-R曲线的以查全率和查准率为坐标轴，其以真正例率(True Positive Rate, TPR)为纵轴、假正例率(False Positive Rate, FPR)为横轴，真正例率和假正例率的定义为：

$$TPR = \frac{TP}{TP+RF}$$

$$FPR = \frac{FP}{TN+FP}$$

可以看出真正例率=查全率，假正例率=1-反例的查全率，下图给出了ROC曲线的示意图，图(a)时理想的曲线，但是测试样例的数量是有限的，因此绘制出来的ROC曲线一般都是图(b)所示的折线图，图中点(0,1)表示将所有的正例排在所有的反例之前的“理想模型”。与P-R曲线类似，如果一个学习器的ROC曲线被另一个学习器的ROC曲线完全包住，则后者优于前者。而当ROC曲线发生交叉时，则需要比较ROC曲线下的面积大小，对应于图中的AUC(Area Under Curve)。

![图2 ROC曲线与AUC](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20190107225253.png)

**评价指标选择**

通过以上分析，可以发现accuracy、precision和recall不适合本项目中的非对称的数据集，因此不再考虑上述三个指标。那么对于F1-Score和AUC这两个指标呢？在《白面机器学习》里，可以看到如下图关于P-R曲线和ROC曲线的对比：

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200603225819.png)

可以看到负样本增加后，P-R曲线的在测试集上的表现变化很大，而来自对P和R求调和平均的F1-Score也会受到测试集分布的影响，因此这里我考虑使用AUC作为模型的评估指标。

### 5.2 模型选择

将数据分为训练集、测试集和验证集。

考虑到在本地进行调参的耗时较长，选择模型时就没有进行调参，直接使用默认参数进行训练，然后根据模型在测试集上的表现选择评价指标最高的模型。

这里使用逻辑回归、随机森林和提升树算法进行建模，三种模型在训练集和测试集上的表现如下表所示：

| 指标      | 逻辑回归 | 随机森林 | 提升树 |
| :-------- | :------- | :------- | :----- |
| 训练集AUC | 0.973    | 0.954    | 1.0    |
| 测试集AUC | 0.532    | 0.832    | 0.905  |

根据模型的评估指标可以发现：

- 逻辑回归的过拟合比较严重，因为没有使用正则化参数；
- 随机森林在训练集上表现不如逻辑回归，但没有出现逻辑回归这样的严重过拟合；
- 提升树在训练集上和测试集上均表现最好，因此选择提升树作为最终预测的模型。

### 5.3 预测结果

提升树模型在验证集上的AUC为0.641，不如模型在测试集上的表现。猜测可能是由于数据集的数量太少，验证集上的部分数据的特性在训练集上没有体现，所以模型在验证集上表现不好。

## 6. 后续工作

- 将代码迁移至分布式服务集群上运行，以便使用完整数据集进行模型训练和模型选择。
- 对模型的超参数进行调整，优化模型。
- 优化特征工程，提升模型的表现。

## 7. 总结和致谢

这个项目作为纳米学位的毕业项目，不再提供一个已经搭建好框架的代码，仅仅提供了数据分析和建模的基本流程，完成该项目基本上属于独立完成一个数据分析的项目。从取数、探索性数据分析、特征工程到建模和评估模型的代码均需要自己独立完成，虽然对于新手这具有一定的挑战性，但是独立完成上述流程对我自己的提升感觉非常大，至少不再依靠框架代码提供思路来进行数据分析了，而是自行完成整个流程。

完成项目的过程中，探索性数据分析是比较耗时的过程，同时也是发掘数据关系的一个有趣的过程，通过探索性分析不断地挖掘出一些和用户流失相关的特征，而这些特征又可以用于特征工程。

最后，感谢优达学城的数据挖掘纳米学位课程让我能有机会学习到数据挖掘领域。

## 8. 参考文献

[1] 周志华. 机器学习 : = Machine learning[M]. 清华大学出版社, 2016.

[2] 葫芦娃. 百面机器学习 [M]. 人民邮电出版社, 2018.

[3] 李航. 统计学习方法[M]. 清华大学出版社, 2012.

[4] <https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/>

[5] <https://en.wikipedia.org/wiki/F1_score>

[6] https://zh.**wikipedia**.org/zh-hans/**ROC**曲线



