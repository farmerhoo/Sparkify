# Sparkify项目报告

## 1. 项目简介

### 1.1 背景

本项目为优达学城数据挖掘纳米学位班的毕业项目，项目是分析一个音乐应用Sparkify的用户流失情况，并根据提供的结构化数据预测用户流失情况。项目既可以在128MB的迷你数据集上完成，也可以选择在完整的12GB的数据集上完成。考虑到便捷性，我这里先使用迷你数据集在本地完成项目，后续可以直接迁移至大型的完整数据集上。

完整数据集高达12GB，不能使用小数据集的scikit-learn、pandas等数据科学包在本地完成处理，因此使用Spark来进行数据的预处理、探索性数据分析(Exploratory Data Analysis, EDA)和建模预测等任务，熟悉通过pyspark包进行大规模的数据分析任务。

### 1.2 项目结构

本项目首先导入项目相关的迷你用户数据集，对数据进行简单的处理发现数据集的大小为286500行18列，也就是说提供的数据包含286500份用户在Sparkify应用程序上的交互数据，每一份数据包含18个特征。接下来我对项目的数据进行清理、删除缺失值和创建用户是否流失的标记列(churn列)等操作，为进一步的探索性数据分析做准备。通过探索性数据分析，初步了解到与用户流失有一定相关性的特征，这些特征就是特征工程中所使用的基础特征，特征工程将上述特征转换为便于机器学习模型训练的特征向量。最后，使用逻辑回归、随机森林和提示树三个模型在训练数据集上预测用户是否流失，并通过模型在测试数据集上的表现选择模型，使用选择的模型对验证集上的数据进行预测，并给出模型预测的评分。

### 1.3 项目代码

项目代码可以在Git-hub上查看：<https://github.com/farmerhoo/Sparkify>

## 2. 初步处理数据

### 2.1 理解特征的实际意义

本次数据分析使用的为迷你数据集，数据大小为$28650 \times 18$

初步查看每个特征后，按照数值型数据和类别型数据给出每个特征的可能取值和实际意义如下所示：
​    - 数值型数据：
​        - userId(string): 用户ID
​        - ts(long): 记录时间的timestamp
​        - sessionId(long): 每次打开app创建一个sessionId
​        - length(double): 歌的长度
​        - itemInSession(long): Session中的项目数量
​        - registration(long): 注册时间timestamp

- 类别型数据：
    - artist(string): 艺术家
    - auth(string): 用户身份验证状态，比如Logged In状态
    - firstName(string): 用户的名字
    - gender(string): 用户性别
    - lastName(string): 用户的姓
    - level(string): 有free和paid两种
    - location(string): 用户的定位
    - method(string): HTTP请求方式，PUT和GET两种
    - page(string): 页面名称，Home, Upgrade, Downgrade等
    - song(string): 歌曲名称
    - status(long): 请求状态，200、307、404这三种
    - userAgent(string): 用户浏览器


### 2.2 清理数据

首先，根据对数据的观察，发现缺失值存在三种情况：1. NaN，Not A Number；2. NULL，空值；3. '', 空字符串。

根据对缺失值的分析发现：userId、firstName、gender、lastName、location、registration、userAgent列的缺失值数量是相同的，可以看出这些特征都是用户的信息；而其他的存在缺失值的特征为artist、length和song，他们的缺失值数量也是相同的，并且可以看出特征均为歌曲相关的信息。

删除缺失值时，因为用户信息列的确实对数据分析影响更大，而且对后续的用户流失分析贡献很小，我们就删除了userId列存在缺失值的所在行，对于歌曲信息列存在缺失值的情况暂时不做处理。

## 3. 探索性数据分析

### 2.1 单变量分析

1. 用户的性别分布如下图，男性用户略多于女性用户。

![图片](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200531225032.png)

2. 用户交互次数的分布如下图所示，可以发现大多数用户的交互次数都在2000以内，个别用户的交互次数特别多，这类用户的流失可能性应该是偏小的。

![1590936757232](C:\Users\huqua\AppData\Roaming\Typora\typora-user-images\1590936757232.png)

3. 打开APP次数的分布直方图如下图所示，从图中可以看出打开APP次数看起来像一个长尾分布或泊松分布，数据集的这段时间内大多数用户打开APP的次数在20次以内。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200601213110.png)

4. 根据单变量的探索性分析，还可以得出如下结论：
   - 本数据集总共有225个独立的用户，流失的用户占比为23.11%
   - 本数据集中在该软件上交互次数最多的用户ID为39
   - 本数据集中用户的交互次数为长尾分布，大多数用户的交互次数在2000次以下
   - 本数据集包含的艺术家数量为17656
   - 本数据集包含的歌曲数量为58481
   - 本数据集播放量最高艺术家是Kings Of Leon
   - 本数据集播放量最高的歌曲是You're The One，排名第二的Undo我也经常听，哈哈
   - 本数据集大多数用户都处于登陆（Logged in）状态
   - 本数据集的用户中男性用户略多余女性用户
   - 本数据集的用户大都在付费状态下进行操作，说明软件的付费比率还是比较高的
   - 本数据集中软件使用量排名最高的三个城市分别是：洛杉矶、纽约和波士顿
   - 本数据集中访问最多的页面是Next Song页面，其次是Thumbs Up点赞页面，再次是Home页面及主页
   - 本数据集中用户的请求有252个返回404，可能存在部分需要修复的页面
   - 本数据集包含用户在2018年10月1日至2018年12月31日的交互数据

### 2.2 多变量分析

1. 如下图所示，流失用户所听艺术家的歌曲数量相对较少。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200601213654.png)

2. 留存用户中男女比例接近，流失用户中男性略多于女性，如下图所示。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200601213745.png)

3. 付过费的用户流失率略低，说明付过费的用户更认可该产品，也可能是因为产品得到了认可才付费的。如下图所示。

![1591018701460](C:\Users\huqua\AppData\Roaming\Typora\typora-user-images\1591018701460.png)

4. 流失用户所听歌曲数量相对较少，如下图所示。

![1591018728108](C:\Users\huqua\AppData\Roaming\Typora\typora-user-images\1591018728108.png)

5. 流失用户添加歌曲至播放清单的数量相对更少，如下图所示。

![1591018746832](C:\Users\huqua\AppData\Roaming\Typora\typora-user-images\1591018746832.png)

6. 流失用户添加朋友的数量相对更少，如下图所示。

![1591018764470](C:\Users\huqua\AppData\Roaming\Typora\typora-user-images\1591018764470.png)

7. 流失用户的交互次数相对更少，如下图所示。

![1591018790850](C:\Users\huqua\AppData\Roaming\Typora\typora-user-images\1591018790850.png)

8. 流失用户打开app的次数相对更少，如下图所示。

![1591018814049](C:\Users\huqua\AppData\Roaming\Typora\typora-user-images\1591018814049.png)

9. 流失用户注册天数明显更短，如下图所示。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200601214030.png)

10. 流失用户注册天数明显更短，如下图所示。

![](https://farmerhoo-blog-1258360101.cos.ap-shanghai.myqcloud.com/img/20200601214100.png)

## 4. 特征工程

根据探索性分析的结果，选取部分特征用于建模。这些特征在训练模型前需要先进行特征工程，将特征转换为适合模型训练的向量类型，以下分为数值型特征和类别型特征分别进行讨论。

### 4.1 数值型特征

根据以上的分析，创建如下几个数值型特征
- 听歌数量(numSongs)：认为每点击一次NextSong表示听歌一首
- 播放清单歌曲数量(numInList)：认为每点击一次Add to PlayList添加一首歌曲
- 添加朋友数量(numFriends)：认为每点击一次Add Friend添加一个朋友
- 打开app次数(numSession)：认为一个新的sessionId表示打开一次app
- 注册天数(regDay)：注册时间到认为最后一次打开app的记录的天数

### 4.2 类别型特征

根据以上分析，创建以下几个类别型特征：
- 性别特征(gender)
- 用户级别(level)
- 用户定位特征(location)，因定位的格式一般为"locPart1, locPart2", 因此分为两部分处理
    - 定位前半部分(locPart1)
    - 定位后半部分(locPart2)

## 5. 建模

### 5.1 评价指标

适合二分类的评估指标有准确率、精确率、召回率、F1和ROC曲线下面积AUC等指标，这里的考虑到样本的非平衡特征，就不考虑准确率、精确率和召回率的指标，而F1指标在测试集和训练集的正负样本出现变化时会出现比较大的波动，因此这里考虑使用AUC作为模型的评估指标。

### 5.2 模型选择

将数据分为训练集、测试集和验证集。

考虑到在本地进行调参的耗时较长，选择模型时就没有进行调参，直接使用默认参数进行训练，然后根据模型在测试集上的表现选择评价指标最高的模型。

这里使用逻辑回归、随机森林和提升树算法进行建模，三种模型在训练集和测试集上的表现如下表所示：

| 指标      | 逻辑回归 | 随机森林 | 提升树 |
| :-------- | :------- | :------- | :----- |
| 训练集AUC | 0.973    | 0.954    | 1.0    |
| 测试集AUC | 0.532    | 0.832    | 0.905  |

根据模型的评估指标可以发现：

- 逻辑回归的过拟合比较严重，因为没有使用正则化参数；
- 随机森林在训练集上表现不如逻辑回归，但没有出现逻辑回归这样的严重过拟合；
- 提升树在训练集上和测试集上均表现最好，因此选择提升树作为最终预测的模型。

### 5.3 预测结果

提升树模型在验证集上的AUC为0.641，不如模型在测试集上的表现。猜测可能是由于数据集的数量太少，验证集上的部分数据的特性在训练集上没有体现，所以模型在验证集上表现不好。

## 6. 后续工作

- 将代码迁移至分布式服务集群上运行，以便使用完整数据集进行模型训练和模型选择。
- 对模型的超参数进行调整，优化模型。
- 优化特征工程，提升模型的表现。

## 7. 致谢

感谢优达学城的数据挖掘纳米学位课程让我能有机会学习到数据挖掘领域。



